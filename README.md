# ğŸ­ Cinematic Avatar Video Generator

## > âš ï¸ This project is currently under development and intended for commercial sale.  
> The code is shared here for review only and is not licensed for reuse or redistribution.


### A lightweight, fully local app that generates cinematic avatar videos using an image and text prompt â€” no API keys, no cloud dependencies.

Built with React, Flask, Coqui TTS, and SadTalker.

---

## ğŸš€ Features

- âœ… Upload or choose an avatar
- âœ… Type a scene prompt (1â€“3 sentences)
- âœ… Choose background and music
- âœ… Generate lip-synced video with voice
- âœ… Download your final result
- âœ… Fully local, no API calls
- âœ… Toggle between Demo Mode and Full Mode

---

## ğŸ§  How It Works

1. **Avatar**: Upload a PNG or JPEG image
2. **Prompt**: User types a short script
3. **TTS**: Coqui TTS converts text to voice
4. **Lip Sync**: SadTalker animates avatar to match speech
5. **Cinematic FX**: Framer Motion animates background/zoom
6. **Music**: Royalty-free background music added
7. **Preview**: Scene parts rendered in-browser with HTML5 & CSS
8. **Download**: Output is downloadable in Full Mode

---

## ğŸ“ Tech Stack

| Frontend          | Backend            |  Media Processing           |
|-------------------|--------------------|-----------------------------|
| React + Bootstrap | Flask + Python     |  Coqui TTS + SadTalker      |
| Framer Motion     | FFmpeg (local use) | HTML5 `<video>` composition |

---

## ğŸ§ª Modes

### ğŸŸ¢ Full Mode
- Runs Coqui TTS and SadTalker locally
- Generates full video with real voice and lip sync

### ğŸ”µ Demo Mode
- Uses pre-generated media files
- Fast testing for UI & animation without compute load

Toggle between modes in the UI.

---

## ğŸ“¦ Setup Instructions

### ğŸ”§ Prerequisites
- Python 3.9+
- Node.js 16+
- FFmpeg installed & added to PATH

### ğŸ› ï¸ Installation

git clone https://github.com/CPericas/Vid_Gen.git
cd Vid_Gen
npm install

cd server
python -m venv .venv

### On Windows PowerShell:
.venv\Scripts\Activate.ps1

### On Windows CMD:
.venv\Scripts\activate.bat

### On macOS/Linux:
source .venv/bin/activate

pip install -r requirements.txt

## âš™ï¸ Full Mode Requirements & Performance Notes
### Hardware Requirements
Running Full Mode locally requires significant CPU and GPU resources due to heavy AI processing by Coqui TTS and SadTalker.
Recommended: A multi-core CPU with at least 16GB RAM and a dedicated GPU will drastically reduce processing time.

### Performance
On typical laptops without a dedicated GPU, video generation can take over an hour per video.
Demo Mode exists to provide a fast, no-wait user experience for UI testing and quick demos by using pre-generated media files.

### Why Demo Mode?

Avoids long processing times on less powerful machines.

Allows instant previews and interaction without GPU or API dependencies.

Makes the MVP accessible and marketable to buyers without expensive hardware.

### For Best Results
Buyers interested in Full Mode should consider upgrading hardware or running on cloud servers to get reasonable video generation times.

## ğŸ§¾ License
This project is released under the MIT License.
Includes royalty-free music from FreePD.com.

## ğŸ’¼ Use Cases
Indie AI video creators

Short-form content tools

Avatar-based storytelling

Educational apps or character bots

## ğŸ“¬ Contact
Created by Chris Pericas
For acquisition or questions, reach out via GitHub or contact directly.





